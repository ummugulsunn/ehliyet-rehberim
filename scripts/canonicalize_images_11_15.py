#!/usr/bin/env python3
"""
Deneme 11-15'teki tekrar eden sorularÄ±n gÃ¶rsellerini, Deneme 1-10 arasÄ± kaynaklara gÃ¶re
kanonik hÃ¢le getirir. Eksik ana gÃ¶rselleri ekler ve farklÄ± olan ana gÃ¶rselleri kaynak gÃ¶rselle deÄŸiÅŸtirir.

AyrÄ±ca varsa seÃ§enek gÃ¶rsellerini de kaynakla eÅŸler.
"""

from __future__ import annotations
import json
import re
from typing import Dict, List, Tuple
from pathlib import Path

EXAMS_FILE = "assets/data/exams.json"
TARGET_EXAMS = [
    "deneme_sinavi_11",
    "deneme_sinavi_12",
    "deneme_sinavi_13",
    "deneme_sinavi_14",
    "deneme_sinavi_15",
]


def normalize_text(text: str) -> str:
    text = text.lower()
    text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def load() -> List[dict]:
    with open(EXAMS_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save(data: List[dict]) -> None:
    with open(EXAMS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def build_source_map(data: List[dict]) -> Dict[str, Tuple[str, Dict[str, str]]]:
    source: Dict[str, Tuple[str, Dict[str, str]]] = {}
    for exam in data:
        if exam.get("examId") in TARGET_EXAMS:
            continue
        for q in exam.get("questions", []):
            qt = q.get("questionText", "")
            if not qt:
                continue
            norm = normalize_text(qt)
            img = q.get("imageUrl")
            if not img or img == "null":
                continue
            opt_imgs: Dict[str, str] = {}
            for k, v in (q.get("options", {}) or {}).items():
                if isinstance(v, dict) and v.get("imageUrl"):
                    opt_imgs[k] = v["imageUrl"]
            source[norm] = (img, opt_imgs)
    return source


def canonicalize(data: List[dict], source_map: Dict[str, Tuple[str, Dict[str, str]]]) -> dict:
    stats = {
        "exams_updated": set(),
        "questions_canonicalized": 0,
        "main_images_added": 0,
        "main_images_replaced": 0,
        "option_images_added": 0,
    }
    for exam in data:
        exam_id = exam.get("examId")
        if exam_id not in TARGET_EXAMS:
            continue
        for q in exam.get("questions", []):
            qt = q.get("questionText", "")
            norm = normalize_text(qt)
            if norm not in source_map:
                continue
            src_img, src_opt_imgs = source_map[norm]
            cur_img = q.get("imageUrl")
            changed = False
            # Ana gÃ¶rseli ekle/deÄŸiÅŸtir
            if not cur_img or cur_img == "null":
                q["imageUrl"] = src_img
                stats["main_images_added"] += 1
                changed = True
            elif cur_img != src_img:
                q["imageUrl"] = src_img
                stats["main_images_replaced"] += 1
                changed = True
            # SeÃ§enek gÃ¶rsellerini uygula (varsa)
            if src_opt_imgs:
                opts = q.get("options", {}) or {}
                for k, rec in src_opt_imgs.items():
                    if k in opts:
                        ov = opts[k]
                        if isinstance(ov, dict):
                            if ov.get("imageUrl") != rec:
                                ov["imageUrl"] = rec
                                stats["option_images_added"] += 1
                                changed = True
                        else:
                            opts[k] = {"text": ov, "imageUrl": rec}
                            stats["option_images_added"] += 1
                            changed = True
                    else:
                        # seÃ§enek anahtarlarÄ± tutmuyorsa atla
                        pass
                q["options"] = opts
            if changed:
                stats["questions_canonicalized"] += 1
                stats["exams_updated"].add(exam_id)
    stats["exams_updated"] = sorted(list(stats["exams_updated"]))
    return stats


def main() -> int:
    if not Path(EXAMS_FILE).exists():
        print(f"âŒ BulunamadÄ±: {EXAMS_FILE}")
        return 1
    data = load()
    source_map = build_source_map(data)
    print(f"ğŸ” Kaynak soru-gÃ¶rsel eÅŸleÅŸmeleri: {len(source_map)}")
    stats = canonicalize(data, source_map)
    if stats["questions_canonicalized"] > 0:
        save(data)
        print("âœ… exams.json gÃ¼ncellendi")
    else:
        print("â„¹ï¸ GÃ¼ncelleme gerekmedi")
    print("\nğŸ“Š Ã–zet:")
    print(f"  - GÃ¼ncellenen denemeler: {', '.join(stats['exams_updated']) if stats['exams_updated'] else 'yok'}")
    print(f"  - KanonikleÅŸtirilen soru sayÄ±sÄ±: {stats['questions_canonicalized']}")
    print(f"  - Eklenen ana gÃ¶rsel: {stats['main_images_added']}")
    print(f"  - DeÄŸiÅŸtirilen ana gÃ¶rsel: {stats['main_images_replaced']}")
    print(f"  - Eklenen/uygulanan seÃ§enek gÃ¶rselleri: {stats['option_images_added']}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
